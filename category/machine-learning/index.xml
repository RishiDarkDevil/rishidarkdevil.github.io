<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Machine Learning | Rishi</title>
    <link>https://rishidarkdevil.github.io/category/machine-learning/</link>
      <atom:link href="https://rishidarkdevil.github.io/category/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    <description>Machine Learning</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Fri, 03 Feb 2023 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://rishidarkdevil.github.io/media/icon_hucf31d7374fc459aedebb55d24d710d3c_248924_512x512_fill_lanczos_center_3.png</url>
      <title>Machine Learning</title>
      <link>https://rishidarkdevil.github.io/category/machine-learning/</link>
    </image>
    
    <item>
      <title>Kernel Density Estimation — A Gentle Introduction to Non-Parametric Statistics</title>
      <link>https://rishidarkdevil.github.io/post/kernel-density-estimation/</link>
      <pubDate>Fri, 03 Feb 2023 00:00:00 +0000</pubDate>
      <guid>https://rishidarkdevil.github.io/post/kernel-density-estimation/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;Normality is a Myth!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Back in the 20th century, when Statistics was still in its infancy and computers weren’t that popular, it was norm to assume normality as the distribution from which data was generated. It was mostly because it made the calculations less tedious in the age when all results were hand calculated.&lt;/p&gt;
&lt;p&gt;But with the rise of computational power these assumptions can safely be put aside and more insights can be drawn directly for the data. Even the availability of data in this Big Data era made Statisticians to adopt more modern techniques — Non-Parametric Statistics. Here we will discuss one such method to estimate the probability distribution, Kernel Density Estimation.&lt;/p&gt;
&lt;p&gt;Read More at: &lt;a href=&#34;https://medium.com/@rishidarkdevil/kernel-density-estimation-a-gentle-introduction-to-non-parametric-statistics-6a5259d26eff&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Kernel Density Estimation — A Gentle Introduction to Non-Parametric Statistics&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Revisiting Logistic Regression — A Gentle Introduction to Generalized Linear Models</title>
      <link>https://rishidarkdevil.github.io/post/logistic-regression/</link>
      <pubDate>Fri, 03 Feb 2023 00:00:00 +0000</pubDate>
      <guid>https://rishidarkdevil.github.io/post/logistic-regression/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;All models are wrong, but some are useful&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The two fundamental pillars of supervised statistical learning — Regression and Classification. Simple Linear Regression and Logistic Regression is how many of us have started our journey in Statistics and Data Science. A long-standing debate still prevails on why is Logistic Regression a Classification Model instead of a Regression Model?&lt;/p&gt;
&lt;p&gt;Here we revisit Logistic Regression from an intuitive perspective along with statistical rigor. We will briefly touch up on the concepts behind Generalized Linear Model along with an optional section on Iterative Re-weighted Least Squares (IRLS) to fit these models.&lt;/p&gt;
&lt;p&gt;Read More at: &lt;a href=&#34;https://medium.com/@rishidarkdevil/revisiting-logistic-regression-a-gentle-introduction-to-generalized-linear-models-27baae1550f&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Revisiting Logistic Regression — A Gentle Introduction to Generalized Linear Models&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
